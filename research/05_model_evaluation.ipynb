{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\success_analytics_courses\\\\internship_project\\\\pulsar_project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "%pwd\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step - 1 : config.yaml completed\n",
    "## step - 2 : params.yaml completed(required in model trainer stage)\n",
    "## step - 3 : constant completed\n",
    "## step - 4 : entity\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfiguration:\n",
    "\n",
    "    root_dir_name: Path\n",
    "    dataset_download_url: str\n",
    "    zip_data_dir_name: Path\n",
    "    unzip_data_dir_name: Path\n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfiguration:\n",
    "\n",
    "    validated_root_dir_name: Path\n",
    "    validated_train_dir: Path\n",
    "    validated_test_dir: Path\n",
    "    validated_status_report_file_name: str\n",
    "    validated_required_files:list\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfiguration:\n",
    "\n",
    "    transformed_root_dir_name: Path\n",
    "    transformed_train_dir: Path\n",
    "    transformed_test_dir: Path\n",
    "    transformed_industrial_data_dir: Path\n",
    "    transformed_preprocess_dir: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfiguration:\n",
    "\n",
    "    trained_model_root_dir_name: Path\n",
    "    trained_model_path_yaml_file: str\n",
    "    trained_model_base_accuracy: float\n",
    "    trained_model_overfit_value: float\n",
    "    trained_model_FPR: float\n",
    "    trained_model_RECALL: float\n",
    "    trained_model_selection:str\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfiguration:\n",
    "\n",
    "    evaluated_model_root_dir_name: Path\n",
    "    evaluated_model_result_file_name: str\n",
    "    evaluated_model_result_file_column_name: list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step - 5 : configuration manager in src config\n",
    "\n",
    "from pulsarclassification.constants import *\n",
    "from pulsarclassification.logging import logging\n",
    "from pulsarclassification.utils.common import read_yaml,create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "\n",
    "    def __init__(self, config_file_path: str = CONFIG_FILE_PATH):\n",
    "        \n",
    "        try:\n",
    "            self.config = read_yaml(CONFIG_FILE_PATH)\n",
    "            create_directories(self.config.artifacts_dir_name)\n",
    "            logging.info(f\" Artifacts directory created at : {self.config.artifacts_dir_name} \")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfiguration:\n",
    "\n",
    "        try:\n",
    "            artifact_dir = self.config.artifacts_dir_name\n",
    "            config = self.config.data_ingestion_config\n",
    "\n",
    "            data_ingestion_dir = os.path.join(artifact_dir,config.root_dir_name)\n",
    "            create_directories(data_ingestion_dir)\n",
    "\n",
    "            raw_data_dir = os.path.join(data_ingestion_dir,config.zip_data_dir_name)\n",
    "            create_directories(raw_data_dir)\n",
    "\n",
    "            ingested_csv_data_dir = os.path.join(data_ingestion_dir,config.unzip_data_dir_name)\n",
    "            create_directories(ingested_csv_data_dir)\n",
    "\n",
    "            data_ingestion_config = DataIngestionConfiguration(\n",
    "                root_dir_name  = config.root_dir_name,\n",
    "                dataset_download_url = config.dataset_download_url,\n",
    "                zip_data_dir_name = raw_data_dir,\n",
    "                unzip_data_dir_name = ingested_csv_data_dir\n",
    "            )\n",
    "\n",
    "            logging.info(f\" Data ingestion configuration: {data_ingestion_config}\")\n",
    "\n",
    "            return data_ingestion_config\n",
    "    \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def get_data_validation_configuration(self) -> DataValidationConfiguration:\n",
    "\n",
    "        try:\n",
    "            artifact_dir = self.config.artifacts_dir_name\n",
    "            config = self.config.data_validation_config\n",
    "\n",
    "            data_validation_dir = os.path.join(artifact_dir,config.validated_root_dir_name)\n",
    "            create_directories(data_validation_dir)\n",
    "\n",
    "            data_validation_train_dir = os.path.join(data_validation_dir,config.validated_train_dir)\n",
    "            create_directories(data_validation_train_dir)\n",
    "\n",
    "            data_validation_test_dir = os.path.join(data_validation_dir,config.validated_test_dir)\n",
    "            create_directories(data_validation_test_dir)\n",
    "\n",
    "            data_validation_config = DataValidationConfiguration(\n",
    "                validated_root_dir_name  = config.validated_root_dir_name,\n",
    "                validated_train_dir = data_validation_train_dir,\n",
    "                validated_test_dir = data_validation_test_dir,\n",
    "                validated_status_report_file_name = os.path.join(data_validation_dir,config.validated_status_report_file_name),\n",
    "                validated_required_files = config.validated_required_files\n",
    "            )\n",
    "\n",
    "            logging.info(f\" Data validation configuration: {data_validation_config}\")\n",
    "\n",
    "            return data_validation_config\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def get_data_transformation_configuration(self) -> DataTransformationConfiguration:\n",
    "\n",
    "        try:\n",
    "            artifact_dir = self.config.artifacts_dir_name\n",
    "            config = self.config.data_transformation_config\n",
    "\n",
    "            data_transformation_dir = os.path.join(artifact_dir,config.transformed_root_dir_name)\n",
    "            create_directories(data_transformation_dir)\n",
    "\n",
    "            data_transformation_train_dir = os.path.join(data_transformation_dir,config.transformed_train_dir)\n",
    "            create_directories(data_transformation_train_dir)\n",
    "\n",
    "            data_transformation_test_dir = os.path.join(data_transformation_dir,config.transformed_test_dir)\n",
    "            create_directories(data_transformation_test_dir)\n",
    "\n",
    "            data_transformation_industrial_data_dir = os.path.join(data_transformation_dir,config.transformed_industrial_data_dir)\n",
    "            create_directories(data_transformation_industrial_data_dir)\n",
    "\n",
    "            data_transformation_preprocess_data_dir = os.path.join(data_transformation_dir,config.transformed_preprocess_dir)\n",
    "            create_directories(data_transformation_preprocess_data_dir)\n",
    "\n",
    "\n",
    "            data_transformation_config = DataTransformationConfiguration(\n",
    "                transformed_root_dir_name = data_transformation_dir,\n",
    "                transformed_train_dir = data_transformation_train_dir,\n",
    "                transformed_test_dir =  data_transformation_test_dir,\n",
    "                transformed_industrial_data_dir =  data_transformation_industrial_data_dir,\n",
    "                transformed_preprocess_dir = data_transformation_preprocess_data_dir\n",
    "            )\n",
    "\n",
    "            logging.info(f\" Data transformation configuration: {data_transformation_config}\")\n",
    "\n",
    "            return data_transformation_config\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def get_model_trainer_configuration(self) -> ModelTrainerConfiguration:\n",
    "\n",
    "        try:\n",
    "            artifact_dir = self.config.artifacts_dir_name\n",
    "            config = self.config.model_trainer_config\n",
    "            param_config = read_yaml(MODEL_PARAMETER_FILE_PATH)\n",
    "\n",
    "            model_trainer_dir = os.path.join(artifact_dir,config.trained_model_root_dir_name)\n",
    "            create_directories(model_trainer_dir)\n",
    "\n",
    "            model_trainer_yaml_file = os.path.join(model_trainer_dir,config[MODEL_TRAINER_YAML_FILE_NAME_KEY])\n",
    "\n",
    "            model_trainer_config = ModelTrainerConfiguration(\n",
    "                trained_model_root_dir_name = model_trainer_dir,\n",
    "                trained_model_path_yaml_file = model_trainer_yaml_file,\n",
    "                trained_model_base_accuracy = config.trained_model_base_accuracy,\n",
    "                trained_model_overfit_value = config.trained_model_overfit_value,\n",
    "                trained_model_FPR           = config.trained_model_FPR,\n",
    "                trained_model_RECALL        = config.trained_model_RECALL,\n",
    "                trained_model_selection     = param_config[MODEL_SELECTION_KEY]\n",
    "            )\n",
    "\n",
    "            logging.info(f\" Model trainer configuration: {model_trainer_config}\")\n",
    "\n",
    "            return model_trainer_config\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def get_model_evaluation_configuration(self) -> ModelEvaluationConfiguration:\n",
    "\n",
    "        try:\n",
    "            artifact_dir = self.config.artifacts_dir_name\n",
    "            config = self.config.model_evaluation_config\n",
    "\n",
    "            model_evaluation_dir = os.path.join(artifact_dir,config.evaluated_model_root_dir_name)\n",
    "            create_directories(model_evaluation_dir)\n",
    "\n",
    "            model_evaluated_csv_file = os.path.join(model_evaluation_dir,config[MODEL_EVALUATION_RESULT_FILE_NAME_KEY])\n",
    "\n",
    "            model_evaluation_config = ModelEvaluationConfiguration(\n",
    "                evaluated_model_root_dir_name = model_evaluation_dir,\n",
    "                evaluated_model_result_file_name = model_evaluated_csv_file,\n",
    "                evaluated_model_result_file_column_name = config.evaluated_model_result_file_column_name\n",
    "            )\n",
    "\n",
    "            logging.info(f\" Model evaluation configuration: {model_evaluation_config}\")\n",
    "\n",
    "            return model_evaluation_config\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage - 6 : updating components\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from pulsarclassification.logging import logging\n",
    "from pulsarclassification.constants import *\n",
    "from pulsarclassification.utils.common import read_yaml\n",
    "from pulsarclassification.entity import DataTransformationConfiguration,ModelTrainerConfiguration\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, \n",
    "                 transformation_config: DataTransformationConfiguration,\n",
    "                 modeltrainer_config: ModelTrainerConfiguration,\n",
    "                 modelevaluation_config: ModelEvaluationConfiguration):\n",
    "\n",
    "        try:\n",
    "            self.transformation_config = transformation_config\n",
    "            self.modeltrainer_config = modeltrainer_config\n",
    "            self.modelevaluation_config = modelevaluation_config\n",
    "            self.schema = read_yaml(SCHEMA_FILE_PATH)\n",
    "        except Exception as e:\n",
    "            raise e \n",
    "        \n",
    "    def get_data_for_evaluation(self):\n",
    "        try:\n",
    "            model_train_data_file_path = os.path.join(self.transformation_config.transformed_train_dir,TRANSFORMED_MODEL_TRAIN_FILE_NAME)\n",
    "            model_test_data_file_path = os.path.join(self.transformation_config.transformed_test_dir,TRANSFORMED_MODEL_TEST_FILE_NAME)\n",
    "            \n",
    "            model_train_data = pd.read_csv(model_train_data_file_path)\n",
    "            model_test_data = pd.read_csv(model_test_data_file_path)\n",
    "\n",
    "            train_data_input_features = model_train_data.drop(self.schema.target_column,axis=1)\n",
    "            logging.info(f\"Train data features extracted from {TRANSFORMED_MODEL_TRAIN_FILE_NAME} having shape : {train_data_input_features.shape} \")\n",
    "\n",
    "            test_data_input_features = model_test_data.drop(self.schema.target_column,axis=1)\n",
    "            logging.info(f\"Test data features extracted from {TRANSFORMED_MODEL_TEST_FILE_NAME} having shape : {test_data_input_features.shape} \")\n",
    "\n",
    "            train_data_output_features = model_train_data[self.schema.target_column]\n",
    "            logging.info(f\"Output feature extracted from {TRANSFORMED_MODEL_TRAIN_FILE_NAME} having shape : {train_data_output_features.shape} \")\n",
    "\n",
    "            test_data_output_features = model_test_data[self.schema.target_column]\n",
    "            logging.info(f\"Output feature extracted from {TRANSFORMED_MODEL_TEST_FILE_NAME} having shape : {test_data_output_features.shape} \")\n",
    "            \n",
    "            return train_data_input_features,train_data_output_features,test_data_input_features,test_data_output_features\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def model_evaluate(self,model,X,y):\n",
    "        y_pred = model.predict(X)\n",
    "        accuracy = accuracy_score(y,y_pred)\n",
    "        tn,fp,fn,tp = confusion_matrix(y, y_pred, labels=[0, 1]).ravel()\n",
    "        FPR = fp/(tn+fp)\n",
    "        RECALL = tp/(tp+fn)\n",
    "        return accuracy,FPR,RECALL\n",
    "\n",
    "    def get_model_evaluation_result(self):\n",
    "        try:\n",
    "            X_train,y_train,X_test,y_test = self.get_data_for_evaluation()  ## X = input features , y = output features\n",
    "            saved_model_config = read_yaml(self.modeltrainer_config.trained_model_path_yaml_file)\n",
    "            print(saved_model_config)\n",
    "            \n",
    "            df_result = pd.DataFrame()\n",
    "            for model_path_key,model_path_name in saved_model_config[SAVED_MODEL_ARTIFACTS_KEY].items():\n",
    "                result = []\n",
    "                model = pd.read_pickle(model_path_name)\n",
    "                train_accuracy,train_fpr,train_recall = self.model_evaluate(model,X_train,y_train)\n",
    "                test_accuracy,test_fpr,test_recall = self.model_evaluate(model,X_test,y_test)\n",
    "                result.append(model_path_name)\n",
    "                result.append(train_accuracy)\n",
    "                result.append(test_accuracy)\n",
    "                result.append(train_fpr)\n",
    "                result.append(test_fpr)\n",
    "                result.append(train_recall)\n",
    "                result.append(test_recall)\n",
    "                model_status = None\n",
    "                if train_accuracy > self.modeltrainer_config.trained_model_base_accuracy :\n",
    "                    if (train_accuracy > test_accuracy) and (test_fpr < self.modeltrainer_config.trained_model_FPR) and (test_recall > self.modeltrainer_config.trained_model_RECALL):\n",
    "                        logging.info(f\" All evaluation cases passed \")\n",
    "                        model_status = 1\n",
    "                    else:\n",
    "                        logging.info(f\" Evaluation cases failed \")\n",
    "                        model_status = 0        \n",
    "                else:\n",
    "                    logging.info(f\" Evaluation cases failed \")\n",
    "                    model_status = 0\n",
    "                    \n",
    "                result.append(model_status)\n",
    "                temp = pd.DataFrame([result])\n",
    "                df_result = pd.concat([df_result,temp],axis=0,ignore_index=True)\n",
    "            df_result.columns = self.modelevaluation_config.evaluated_model_result_file_column_name\n",
    "            df_result.to_csv(self.modelevaluation_config.evaluated_model_result_file_name,index=False)\n",
    "            logging.info(f\" Model result saved in : {self.modelevaluation_config.evaluated_model_result_file_name} \")\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03-09-2023 19:48:23: INFO: common:  yaml file from this path g:\\success_analytics_courses\\internship_project\\pulsar_project\\config\\config.yaml read succesfully]\n",
      "[03-09-2023 19:48:23: INFO: common:  Directory already present: artifacts ]\n",
      "[03-09-2023 19:48:23: INFO: 3903250859:  Artifacts directory created at : artifacts ]\n",
      "[03-09-2023 19:48:23: INFO: common:  Directory already present: artifacts\\data_transformation ]\n",
      "[03-09-2023 19:48:23: INFO: common:  Directory already present: artifacts\\data_transformation\\training_data_for_model ]\n",
      "[03-09-2023 19:48:23: INFO: common:  Directory already present: artifacts\\data_transformation\\test_data_for_model ]\n",
      "[03-09-2023 19:48:23: INFO: common:  Directory already present: artifacts\\data_transformation\\industrial_test_data ]\n",
      "[03-09-2023 19:48:23: INFO: common:  Directory already present: artifacts\\data_transformation\\preprocessed_pickle_file ]\n",
      "[03-09-2023 19:48:23: INFO: 3903250859:  Data transformation configuration: DataTransformationConfiguration(transformed_root_dir_name='artifacts\\\\data_transformation', transformed_train_dir='artifacts\\\\data_transformation\\\\training_data_for_model', transformed_test_dir='artifacts\\\\data_transformation\\\\test_data_for_model', transformed_industrial_data_dir='artifacts\\\\data_transformation\\\\industrial_test_data', transformed_preprocess_dir='artifacts\\\\data_transformation\\\\preprocessed_pickle_file')]\n",
      "[03-09-2023 19:48:23: INFO: common:  yaml file from this path g:\\success_analytics_courses\\internship_project\\pulsar_project\\config\\params.yaml read succesfully]\n",
      "[03-09-2023 19:48:23: INFO: common:  Directory already present: artifacts\\trained_model ]\n",
      "[03-09-2023 19:48:23: INFO: 3903250859:  Model trainer configuration: ModelTrainerConfiguration(trained_model_root_dir_name='artifacts\\\\trained_model', trained_model_path_yaml_file='artifacts\\\\trained_model\\\\trained_model_path.yaml', trained_model_base_accuracy=0.95, trained_model_overfit_value=0.05, trained_model_FPR=0.01, trained_model_RECALL=0.9, trained_model_selection=ConfigBox({'module_0': {'classifier': 'LGBMClassifier', 'module': 'lightgbm', 'params': {'n_estimators': 100, 'random_state': 0}}, 'module_1': {'classifier': 'XGBClassifier', 'module': 'xgboost', 'params': {'n_estimators': 50, 'random_state': 0}}}))]\n",
      "[03-09-2023 19:48:23: INFO: common:  Directory already present: artifacts\\evaluated_model_status ]\n",
      "[03-09-2023 19:48:23: INFO: 3903250859:  Model evaluation configuration: ModelEvaluationConfiguration(evaluated_model_root_dir_name='artifacts\\\\evaluated_model_status', evaluated_model_result_file_name='artifacts\\\\evaluated_model_status\\\\evaluated_model_result.csv', evaluated_model_result_file_column_name=BoxList(['model_path', 'train_accuracy', 'test_accuracy', 'train_fpr', 'test_fpr', 'train_recall', 'test_recall', 'status']))]\n",
      "[03-09-2023 19:48:23: INFO: common:  yaml file from this path g:\\success_analytics_courses\\internship_project\\pulsar_project\\config\\schema.yaml read succesfully]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03-09-2023 19:48:24: INFO: 460011214: Train data features extracted from pulsar_train_data.csv having shape : (105807, 8) ]\n",
      "[03-09-2023 19:48:24: INFO: 460011214: Test data features extracted from pulsar_test_data.csv having shape : (11757, 8) ]\n",
      "[03-09-2023 19:48:24: INFO: 460011214: Output feature extracted from pulsar_train_data.csv having shape : (105807,) ]\n",
      "[03-09-2023 19:48:24: INFO: 460011214: Output feature extracted from pulsar_test_data.csv having shape : (11757,) ]\n",
      "[03-09-2023 19:48:24: INFO: common:  yaml file from this path artifacts\\trained_model\\trained_model_path.yaml read succesfully]\n",
      "{'all_trained_model_paths': {'model_0_path_03092023': 'artifacts\\\\trained_model\\\\model_03092023\\\\LGBMClassifier\\\\model.pkl', 'model_1_path_03092023': 'artifacts\\\\trained_model\\\\model_03092023\\\\XGBClassifier\\\\model.pkl'}}\n",
      "[03-09-2023 19:48:24: INFO: 460011214:  All evaluation cases passed ]\n",
      "[03-09-2023 19:48:25: INFO: 460011214:  All evaluation cases passed ]\n",
      "[03-09-2023 19:48:25: INFO: 460011214:  Model result saved in : artifacts\\evaluated_model_status\\evaluated_model_result.csv ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_configuration()\n",
    "    model_trainer_config = config.get_model_trainer_configuration()\n",
    "    model_evaluation_config = config.get_model_evaluation_configuration()\n",
    "    model_evaluator = ModelEvaluation(transformation_config=data_transformation_config,\n",
    "                                 modeltrainer_config = model_trainer_config,\n",
    "                                 modelevaluation_config=model_evaluation_config)\n",
    "    model_evaluator.get_model_evaluation_result()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
