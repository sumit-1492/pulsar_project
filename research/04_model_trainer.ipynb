{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\success_analytics_courses\\\\internship_project\\\\pulsar_project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step - 1 : config.yaml completed\n",
    "## step - 2 : params.yaml completed(required in model trainer stage)\n",
    "## step - 3 : constant completed\n",
    "## step - 4 : entity\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfiguration:\n",
    "\n",
    "    root_dir_name: Path\n",
    "    dataset_download_url: str\n",
    "    zip_data_dir_name: Path\n",
    "    unzip_data_dir_name: Path\n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfiguration:\n",
    "\n",
    "    validated_root_dir_name: Path\n",
    "    validated_train_dir: Path\n",
    "    validated_test_dir: Path\n",
    "    validated_status_report_file_name: str\n",
    "    validated_required_files:list\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfiguration:\n",
    "\n",
    "    transformed_root_dir_name: Path\n",
    "    transformed_train_dir: Path\n",
    "    transformed_test_dir: Path\n",
    "    transformed_industrial_data_dir: Path\n",
    "    transformed_preprocess_dir: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfiguration:\n",
    "\n",
    "    trained_model_root_dir_name: Path\n",
    "    trained_model_path_yaml_file: Path\n",
    "    trained_model_base_accuracy: float\n",
    "    trained_model_overfit_value: float\n",
    "    trained_model_FPR: float\n",
    "    trained_model_RECALL: float\n",
    "    trained_model_selection:str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step - 5 : configuration manager in src config\n",
    "\n",
    "from pulsarclassification.constants import *\n",
    "from pulsarclassification.logging import logging\n",
    "from pulsarclassification.utils.common import read_yaml,create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "\n",
    "    def __init__(self, config_file_path: str = CONFIG_FILE_PATH):\n",
    "        \n",
    "        try:\n",
    "            self.config = read_yaml(CONFIG_FILE_PATH)\n",
    "            create_directories(self.config.artifacts_dir_name)\n",
    "            logging.info(f\" Artifacts directory created at : {self.config.artifacts_dir_name} \")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfiguration:\n",
    "\n",
    "        try:\n",
    "            artifact_dir = self.config.artifacts_dir_name\n",
    "            config = self.config.data_ingestion_config\n",
    "\n",
    "            data_ingestion_dir = os.path.join(artifact_dir,config.root_dir_name)\n",
    "            create_directories(data_ingestion_dir)\n",
    "\n",
    "            raw_data_dir = os.path.join(data_ingestion_dir,config.zip_data_dir_name)\n",
    "            create_directories(raw_data_dir)\n",
    "\n",
    "            ingested_csv_data_dir = os.path.join(data_ingestion_dir,config.unzip_data_dir_name)\n",
    "            create_directories(ingested_csv_data_dir)\n",
    "\n",
    "            data_ingestion_config = DataIngestionConfiguration(\n",
    "                root_dir_name  = config.root_dir_name,\n",
    "                dataset_download_url = config.dataset_download_url,\n",
    "                zip_data_dir_name = raw_data_dir,\n",
    "                unzip_data_dir_name = ingested_csv_data_dir\n",
    "            )\n",
    "\n",
    "            logging.info(f\" Data ingestion configuration: {data_ingestion_config}\")\n",
    "\n",
    "            return data_ingestion_config\n",
    "    \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def get_data_validation_configuration(self) -> DataValidationConfiguration:\n",
    "\n",
    "        try:\n",
    "            artifact_dir = self.config.artifacts_dir_name\n",
    "            config = self.config.data_validation_config\n",
    "\n",
    "            data_validation_dir = os.path.join(artifact_dir,config.validated_root_dir_name)\n",
    "            create_directories(data_validation_dir)\n",
    "\n",
    "            data_validation_train_dir = os.path.join(data_validation_dir,config.validated_train_dir)\n",
    "            create_directories(data_validation_train_dir)\n",
    "\n",
    "            data_validation_test_dir = os.path.join(data_validation_dir,config.validated_test_dir)\n",
    "            create_directories(data_validation_test_dir)\n",
    "\n",
    "            data_validation_config = DataValidationConfiguration(\n",
    "                validated_root_dir_name  = config.validated_root_dir_name,\n",
    "                validated_train_dir = data_validation_train_dir,\n",
    "                validated_test_dir = data_validation_test_dir,\n",
    "                validated_status_report_file_name = os.path.join(data_validation_dir,config.validated_status_report_file_name),\n",
    "                validated_required_files = config.validated_required_files\n",
    "            )\n",
    "\n",
    "            logging.info(f\" Data validation configuration: {data_validation_config}\")\n",
    "\n",
    "            return data_validation_config\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def get_data_transformation_configuration(self) -> DataTransformationConfiguration:\n",
    "\n",
    "        try:\n",
    "            artifact_dir = self.config.artifacts_dir_name\n",
    "            config = self.config.data_transformation_config\n",
    "\n",
    "            data_transformation_dir = os.path.join(artifact_dir,config.transformed_root_dir_name)\n",
    "            create_directories(data_transformation_dir)\n",
    "\n",
    "            data_transformation_train_dir = os.path.join(data_transformation_dir,config.transformed_train_dir)\n",
    "            create_directories(data_transformation_train_dir)\n",
    "\n",
    "            data_transformation_test_dir = os.path.join(data_transformation_dir,config.transformed_test_dir)\n",
    "            create_directories(data_transformation_test_dir)\n",
    "\n",
    "            data_transformation_industrial_data_dir = os.path.join(data_transformation_dir,config.transformed_industrial_data_dir)\n",
    "            create_directories(data_transformation_industrial_data_dir)\n",
    "\n",
    "            data_transformation_preprocess_data_dir = os.path.join(data_transformation_dir,config.transformed_preprocess_dir)\n",
    "            create_directories(data_transformation_preprocess_data_dir)\n",
    "\n",
    "\n",
    "            data_transformation_config = DataTransformationConfiguration(\n",
    "                transformed_root_dir_name = data_transformation_dir,\n",
    "                transformed_train_dir = data_transformation_train_dir,\n",
    "                transformed_test_dir =  data_transformation_test_dir,\n",
    "                transformed_industrial_data_dir =  data_transformation_industrial_data_dir,\n",
    "                transformed_preprocess_dir = data_transformation_preprocess_data_dir\n",
    "            )\n",
    "\n",
    "            logging.info(f\" Data transformation configuration: {data_transformation_config}\")\n",
    "\n",
    "            return data_transformation_config\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def get_model_trainer_configuration(self) -> ModelTrainerConfiguration:\n",
    "\n",
    "        try:\n",
    "            artifact_dir = self.config.artifacts_dir_name\n",
    "            config = self.config.model_trainer_config\n",
    "            param_config = read_yaml(MODEL_PARAMETER_FILE_PATH)\n",
    "\n",
    "            model_trainer_dir = os.path.join(artifact_dir,config.trained_model_root_dir_name)\n",
    "            create_directories(model_trainer_dir)\n",
    "\n",
    "            model_trainer_yaml_file = Path(os.path.join(model_trainer_dir,config[MODEL_TRAINER_YAML_FILE_NAME_KEY]))\n",
    "\n",
    "            model_trainer_config = ModelTrainerConfiguration(\n",
    "                trained_model_root_dir_name = model_trainer_dir,\n",
    "                trained_model_path_yaml_file = model_trainer_yaml_file,\n",
    "                trained_model_base_accuracy = config.trained_model_base_accuracy,\n",
    "                trained_model_overfit_value = config.trained_model_overfit_value,\n",
    "                trained_model_FPR           = config.trained_model_FPR,\n",
    "                trained_model_RECALL        = config.trained_model_RECALL,\n",
    "                trained_model_selection     = param_config[MODEL_SELECTION_KEY]\n",
    "            )\n",
    "\n",
    "            logging.info(f\" Model trainer configuration: {model_trainer_config}\")\n",
    "\n",
    "            return model_trainer_config\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage - 6 : updating components\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from pulsarclassification.logging import logging\n",
    "from pulsarclassification.constants import *\n",
    "from pulsarclassification.utils.common import read_yaml,create_directories,get_file_size,pickle_file_saving,write_yaml\n",
    "from pulsarclassification.entity import DataIngestionConfiguration,DataValidationConfiguration,DataTransformationConfiguration\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, \n",
    "                 transformation_config: DataTransformationConfiguration,\n",
    "                 modeltrainer_config: ModelTrainerConfiguration):\n",
    "\n",
    "        try:\n",
    "            self.transformation_config = transformation_config\n",
    "            self.modeltrainer_config = modeltrainer_config\n",
    "            self.schema = read_yaml(SCHEMA_FILE_PATH)\n",
    "        except Exception as e:\n",
    "            raise e \n",
    "        \n",
    "    def get_data_for_training(self):\n",
    "        try:\n",
    "            model_train_data_file_path = os.path.join(self.transformation_config.transformed_train_dir,TRANSFORMED_MODEL_TRAIN_FILE_NAME)\n",
    "            model_test_data_file_path = os.path.join(self.transformation_config.transformed_test_dir,TRANSFORMED_MODEL_TEST_FILE_NAME)\n",
    "            \n",
    "            model_train_data = pd.read_csv(model_train_data_file_path)\n",
    "            model_test_data = pd.read_csv(model_test_data_file_path)\n",
    "\n",
    "            input_features = model_train_data.drop(self.schema.target_column,axis=1)\n",
    "            logging.info(f\"Input features extracted from {TRANSFORMED_MODEL_TRAIN_FILE_NAME} having shape : {input_features.shape} \")\n",
    "            output_features = model_train_data[self.schema.target_column]\n",
    "            logging.info(f\"Output feature extracted from {TRANSFORMED_MODEL_TRAIN_FILE_NAME} having shape : {output_features.shape} \")\n",
    "            \n",
    "            return input_features,output_features\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def get_model(self,modellibrary,classificationmodel,modelparameters,inputfeatures,outputfeatures):\n",
    "        try:\n",
    "            #CURRENT_TIME_STAMP = f\"{datetime.now().strftime('%d-%m-%Y-%H-%M-%S')}\"\n",
    "            mllibrary = importlib.import_module(modellibrary)\n",
    "            mlmodel = getattr(mllibrary, classificationmodel)\n",
    "            model = mlmodel(**modelparameters)\n",
    "            model.fit(inputfeatures,outputfeatures)\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def save_model(self):\n",
    "        try:\n",
    "            saved_model_artifacts = {SAVED_MODEL_ARTIFACTS_KEY :{}}\n",
    "            X,y = self.get_data_for_training()  ## X = input features , y = output features\n",
    "\n",
    "            model_saving_folder_name = os.path.join(self.modeltrainer_config.trained_model_root_dir_name,SAVED_MODEL_FOLDER_KEY)\n",
    "            create_directories(model_saving_folder_name)\n",
    "\n",
    "            number_of_model_for_train = []\n",
    "            for key,value in self.modeltrainer_config.trained_model_selection.items():\n",
    "                number_of_model_for_train.append(key)\n",
    "\n",
    "            logging.info(f\"Number of model to train : {len(number_of_model_for_train)}\")\n",
    "\n",
    "            for i in range(len(number_of_model_for_train)):\n",
    "\n",
    "                model_selection = self.modeltrainer_config.trained_model_selection[number_of_model_for_train[i]]\n",
    "                \n",
    "                logging.info(f\"{model_selection[MODEL_CLASSIFIER_KEY]} training started\")\n",
    "                \n",
    "                trained_model = self.get_model(model_selection[MODEL_CLASSIFIER_MODULE_KEY],\n",
    "                                            model_selection[MODEL_CLASSIFIER_KEY],\n",
    "                                            model_selection[MODEL_CLASSIFIER_PARAMETER_KEY],\n",
    "                                            X,y)\n",
    "            \n",
    "                trained_model_saving_path = os.path.join(model_saving_folder_name,model_selection[MODEL_CLASSIFIER_KEY])\n",
    "                create_directories(trained_model_saving_path)\n",
    "                pickle_file_saving(trained_model,trained_model_saving_path,TRAINED_MODEL_FILE_NAME)\n",
    "                trained_model_path = os.path.join(trained_model_saving_path,TRAINED_MODEL_FILE_NAME)\n",
    "                key_of_path = f\"model_{i}_path_{CURRENT_DATE_STAMP}\"\n",
    "                trained_model_artifacts = {key_of_path:Path(trained_model_path)}\n",
    "                saved_model_artifacts[SAVED_MODEL_ARTIFACTS_KEY].update(trained_model_artifacts)\n",
    "            \n",
    "                logging.info(f\"{model_selection[MODEL_CLASSIFIER_KEY]} training completed\")\n",
    "\n",
    "            write_yaml(self.modeltrainer_config.trained_model_path_yaml_file,saved_model_artifacts)\n",
    "            logging.info(f\"Model paths updated in yaml file: {self.modeltrainer_config.trained_model_path_yaml_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03-09-2023 09:43:23: INFO: common:  yaml file from this path g:\\success_analytics_courses\\internship_project\\pulsar_project\\config\\config.yaml read succesfully]\n",
      "[03-09-2023 09:43:23: INFO: common:  yaml file from this path g:\\success_analytics_courses\\internship_project\\pulsar_project\\config\\params.yaml read succesfully]\n",
      "[03-09-2023 09:43:23: INFO: common:  Directory already present: artifacts ]\n",
      "[03-09-2023 09:43:23: INFO: 2280857492:  Artifacts directory created at : artifacts ]\n",
      "[03-09-2023 09:43:23: INFO: common:  Directory already present: artifacts\\data_transformation ]\n",
      "[03-09-2023 09:43:23: INFO: common:  Directory already present: artifacts\\data_transformation\\training_data_for_model ]\n",
      "[03-09-2023 09:43:23: INFO: common:  Directory already present: artifacts\\data_transformation\\test_data_for_model ]\n",
      "[03-09-2023 09:43:23: INFO: common:  Directory already present: artifacts\\data_transformation\\industrial_test_data ]\n",
      "[03-09-2023 09:43:23: INFO: common:  Directory already present: artifacts\\data_transformation\\preprocessed_pickle_file ]\n",
      "[03-09-2023 09:43:23: INFO: 2280857492:  Data transformation configuration: DataTransformationConfiguration(transformed_root_dir_name='artifacts\\\\data_transformation', transformed_train_dir='artifacts\\\\data_transformation\\\\training_data_for_model', transformed_test_dir='artifacts\\\\data_transformation\\\\test_data_for_model', transformed_industrial_data_dir='artifacts\\\\data_transformation\\\\industrial_test_data', transformed_preprocess_dir='artifacts\\\\data_transformation\\\\preprocessed_pickle_file')]\n",
      "[03-09-2023 09:43:23: INFO: common:  Directory already present: artifacts\\trained_model ]\n",
      "[03-09-2023 09:43:23: INFO: 2280857492:  Model trainer configuration: ModelTrainerConfiguration(trained_model_root_dir_name='artifacts\\\\trained_model', trained_model_path_yaml_file='artifacts\\\\trained_model\\\\trained_model_path_yaml_file', trained_model_base_accuracy=0.95, trained_model_overfit_value=0.05, trained_model_FPR=0.01, trained_model_RECALL=0.9, trained_model_selection=ConfigBox({'module_0': {'classifier': 'LGBMClassifier', 'module': 'lightgbm', 'params': {'n_estimators': 100, 'random_state': 0}}, 'module_1': {'classifier': 'XGBClassifier', 'module': 'xgboost', 'params': {'n_estimators': 50, 'random_state': 0}}}))]\n",
      "[03-09-2023 09:43:23: INFO: common:  yaml file from this path g:\\success_analytics_courses\\internship_project\\pulsar_project\\config\\schema.yaml read succesfully]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03-09-2023 09:43:23: INFO: 3737684590: Input features extracted from pulsar_train_data.csv having shape : (105807, 8) ]\n",
      "[03-09-2023 09:43:23: INFO: 3737684590: Output feature extracted from pulsar_train_data.csv having shape : (105807,) ]\n",
      "[03-09-2023 09:43:23: INFO: common:  Directory already present: artifacts\\trained_model\\model_03092023 ]\n",
      "[03-09-2023 09:43:23: INFO: 3737684590: Number of model to train : 2]\n",
      "[03-09-2023 09:43:23: INFO: 3737684590: LGBMClassifier training started]\n",
      "[LightGBM] [Info] Number of positive: 9870, number of negative: 95937\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2040\n",
      "[LightGBM] [Info] Number of data points in the train set: 105807, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.093283 -> initscore=-2.274192\n",
      "[LightGBM] [Info] Start training from score -2.274192\n",
      "[03-09-2023 09:43:24: INFO: common:  Directory already present: artifacts\\trained_model\\model_03092023\\LGBMClassifier ]\n",
      "[03-09-2023 09:43:24: INFO: 3737684590: LGBMClassifier training completed]\n",
      "[03-09-2023 09:43:24: INFO: 3737684590: XGBClassifier training started]\n",
      "[03-09-2023 09:43:32: INFO: common:  Directory already present: artifacts\\trained_model\\model_03092023\\XGBClassifier ]\n",
      "[03-09-2023 09:43:32: INFO: 3737684590: XGBClassifier training completed]\n",
      "[03-09-2023 09:43:32: INFO: 3737684590: Model paths updated in yaml file: artifacts\\trained_model\\trained_model_path_yaml_file]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_configuration()\n",
    "    model_trainer_config = config.get_model_trainer_configuration()\n",
    "    model_trainer = ModelTrainer(transformation_config=data_transformation_config,\n",
    "                                 modeltrainer_config = model_trainer_config)\n",
    "    model_trainer.save_model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
